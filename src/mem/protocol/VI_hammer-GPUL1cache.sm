
machine(L1CacheVI, "VI L1 Cache", genericType="L1Cache")
: Sequencer * sequencer,
  CacheMemory * cacheMemory,
  int l2_select_num_bits,
  int num_l2,
  int issue_latency = 416,
{

  // NETWORK BUFFERS
  MessageBuffer requestFromL1Cache, network="To", virtual_network="7", ordered="true", vnet_type="request";
  MessageBuffer atomicRequestFromL1Cache, network="To", virtual_network="8", ordered="true", vnet_type="request";

  MessageBuffer responseToL1Cache, network="From", virtual_network="6", ordered="true", vnet_type="response";

  // STATES
  state_declaration(State, desc="Cache states") {
    I, AccessPermission:Invalid, desc="Not Present/Invalid";
    V, AccessPermission:Read_Only, desc="Valid";

    IA, AccessPermission:Busy, desc="Invalid, but waiting for ack from L2";

    V_a, AccessPermission:Read_Only, desc="Valid waiting for other atomic (locked & blocking)";
    VI_a, AccessPermission:Busy, desc="Modified by atomic, issued PUT";

    IV, AccessPermission:Busy, desc="Issued request for LOAD/IFETCH";
    IV_a, AccessPermission:Busy, desc="Issued request for LOAD/IFETCH for atomic";
  }

  // EVENTS
  enumeration(Event, desc="Cache events") {
    // From processor

    Load,       desc="Load request from processor";
    Ifetch,     desc="Ifetch request from processor";
    Store,      desc="Store request from processor";
    Flush_line, desc="Invalidate the line if valid";

    Atomic,     desc="Atomic request from processor";

    Data,       desc="Data from network";

    //Inv,        desc="Invalidate request from dir";

    Replacement,  desc="Replace a block";
    Writeback_Ack,   desc="Ack from the directory for a writeback";
  }

  enumeration(RequestType, desc="Type of request for each transition") {
    DataArrayRead,    desc="L1 Data array read";
    DataArrayWrite,   desc="L1 Data array write";
    TagArrayRead,     desc="L1 Tag array read";
    TagArrayWrite,    desc="L1 Tag array write";
  }

  // STRUCTURE DEFINITIONS

  MessageBuffer mandatoryQueue, ordered="false";

  // CacheEntry
  structure(Entry, desc="...", interface="AbstractCacheEntry") {
    State CacheState,        desc="cache state";
    bool Dirty,              desc="Is the data dirty (different than memory)?";
    DataBlock DataBlk,       desc="Data in the block";
  }


  // TBE fields
  structure(TBE, desc="...") {
    State TBEState,          desc="Transient state";
    DataBlock DataBlk,       desc="data for the block, required for concurrent writebacks";
  }

  structure(TBETable, external="yes") {
    TBE lookup(Address);
    void allocate(Address);
    void deallocate(Address);
    bool isPresent(Address);
  }


  // STRUCTURES

  TBETable TBEs, template="<L1CacheVI_TBE>";

  // needed for writeCallback to work. The data stored here is ignored
  DataBlock temp_store_data;

  // PROTOTYPES
  void set_cache_entry(AbstractCacheEntry a);
  void unset_cache_entry();
  void set_tbe(TBE b);
  void unset_tbe();
  void wakeUpAllBuffers();
  void wakeUpBuffers(Address a);

  // for profiling
  void profileGPUL1Access(bool isRead, bool isHit, NodeID version);

  Entry getCacheEntry(Address address), return_by_pointer="yes" {
    return static_cast(Entry, "pointer", cacheMemory.lookup(address));
  }


  int l2_select_low_bit, default="RubySystem::getBlockSizeBits()";

  // External functions
  MachineID getL2ID(Address num, int num_l2, int select_bits, int select_start_bit);

  // FUNCTIONS
  Event mandatory_request_type_to_event(RubyRequestType type) {
   if (type == RubyRequestType:LD) {
      return Event:Load;
    } else if (type == RubyRequestType:IFETCH) {
      return Event:Ifetch;
    } else if (type == RubyRequestType:ST)  {
      return Event:Store;
    } else if ((type == RubyRequestType:FLUSH)) {
      return Event:Flush_line;
    } else if (type == RubyRequestType:ATOMIC) {
      return Event:Atomic;
    } else {
      error("Invalid RubyRequestType");
    }
  }

  State getState(TBE tbe, Entry cache_entry, Address addr) {

    if (is_valid(tbe)) {
      return tbe.TBEState;
    }
    else if (is_valid(cache_entry)) {
      return cache_entry.CacheState;
    }
    else {
      return State:I;
    }
  }

  void setState(TBE tbe, Entry cache_entry, Address addr, State state) {

    if (is_valid(tbe)) {
      tbe.TBEState := state;
    }

    if (is_valid(cache_entry)) {
      cache_entry.CacheState := state;
    }
  }

  AccessPermission getAccessPermission(Address addr) {
    TBE tbe := TBEs[addr];
    if(is_valid(tbe)) {
      return L1CacheVI_State_to_permission(tbe.TBEState);
    }

    Entry cache_entry := getCacheEntry(addr);
    if(is_valid(cache_entry)) {
      return L1CacheVI_State_to_permission(cache_entry.CacheState);
    }

    return AccessPermission:NotPresent;
  }

  void setAccessPermission(Entry cache_entry, Address addr, State state) {
    if (is_valid(cache_entry)) {
      cache_entry.changePermission(L1CacheVI_State_to_permission(state));
    }
  }

  DataBlock getDataBlock(Address addr), return_by_ref="yes" {
    Entry cache_entry := getCacheEntry(addr);
    if(is_valid(cache_entry)) {
        return cache_entry.DataBlk;
    }

    TBE tbe := TBEs[addr];
    if(is_valid(tbe)) {
      return tbe.DataBlk;
    }

    error("Missing data block");
  }

  GenericMachineType getNondirectHitMachType(MachineID sender) {
    if (machineIDToMachineType(sender) == MachineType:L1Cache) {
      //
      // NOTE direct local hits should not call this
      //
      // return L1 with cache coherence if CPU had the data
      return GenericMachineType:L1Cache_wCC;
    } else {
      return ConvertMachToGenericMach(machineIDToMachineType(sender));
    }
  }

  void recordRequestType(RequestType type, Address addr) {
    if (type == RequestType:DataArrayRead) {
      cacheMemory.recordRequestType(CacheRequestType:DataArrayRead);
    } else if (type == RequestType:DataArrayWrite) {
      cacheMemory.recordRequestType(CacheRequestType:DataArrayWrite);
    } else if (type == RequestType:TagArrayRead) {
      cacheMemory.recordRequestType(CacheRequestType:TagArrayRead);
    } else if (type == RequestType:TagArrayWrite) {
      cacheMemory.recordRequestType(CacheRequestType:TagArrayWrite);
    } else {
      error("Bad request type passed to recordRequestType");
    }
  }

  bool checkResourceAvailable(RequestType type, Address addr) {
    if (type == RequestType:DataArrayRead) {
      return cacheMemory.checkResourceAvailable(CacheResourceType:DataArray, addr);
    } else if (type == RequestType:DataArrayWrite) {
      return cacheMemory.checkResourceAvailable(CacheResourceType:DataArray, addr);
    } else if (type == RequestType:TagArrayRead) {
      return cacheMemory.checkResourceAvailable(CacheResourceType:TagArray, addr);
    } else if (type == RequestType:TagArrayWrite) {
      return cacheMemory.checkResourceAvailable(CacheResourceType:TagArray, addr);
    } else {
      error("Bad request type passed to checkResourceAvailable");
    }
  }

  // NETWORK PORTS

  out_port(requestNetwork_out, RequestMsgVI, requestFromL1Cache);
  out_port(requestNetworkAtomic_out, RequestMsgVI, atomicRequestFromL1Cache);

  in_port(responseNetwork_in, ResponseMsgVI, responseToL1Cache) {
    if (responseNetwork_in.isReady()) {
      peek(responseNetwork_in, ResponseMsgVI, block_on="Address") {

        Entry cache_entry := getCacheEntry(in_msg.Address);
        TBE tbe := TBEs[in_msg.Address];

        if (in_msg.Type == CoherenceResponseTypeVI:DATA) {
          trigger(Event:Data, in_msg.Address, cache_entry, tbe);
        } else if (in_msg.Type == CoherenceResponseTypeVI:WB_ACK) {
          trigger(Event:Writeback_Ack, in_msg.Address, cache_entry, tbe);
        } else {
          error("Unexpected message");
        }
      }
    }
  }

    // Mandatory Queue
  in_port(mandatoryQueue_in, RubyRequest, mandatoryQueue, desc="...") {
    if (mandatoryQueue_in.isReady()) {
      peek(mandatoryQueue_in, RubyRequest, block_on="LineAddress") {

        Entry cache_entry := getCacheEntry(in_msg.LineAddress);
        // No need to replace on store since stores do not write into the cache
        if (is_invalid(cache_entry) &&
            cacheMemory.cacheAvail(in_msg.LineAddress) == false &&
            in_msg.Type != RubyRequestType:ST) {
          // make room for the block
          trigger(Event:Replacement, cacheMemory.cacheProbe(in_msg.LineAddress),
                  getCacheEntry(cacheMemory.cacheProbe(in_msg.LineAddress)),
                  TBEs[cacheMemory.cacheProbe(in_msg.LineAddress)]);
        }
        else {
          trigger(mandatory_request_type_to_event(in_msg.Type), in_msg.LineAddress,
                  cache_entry, TBEs[in_msg.LineAddress]);
        }
      }
    }
  }

  // ACTIONS

  action(a_issueRequest, "a", desc="Issue a request") {
    enqueue(requestNetwork_out, RequestMsgVI, latency=issue_latency) {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestTypeVI:GET;
      out_msg.Requestor := machineID;
      out_msg.Destination.add(getL2ID(address, num_l2, l2_select_num_bits, l2_select_low_bit));
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }

  action(b_issuePUT, "b", desc="Issue a PUT request") {
    peek(mandatoryQueue_in, RubyRequest) {
      enqueue(requestNetwork_out, RequestMsgVI, latency=issue_latency) {
        out_msg.Address := address;
        out_msg.Type := CoherenceRequestTypeVI:PUT;
        out_msg.Requestor := machineID;
        out_msg.Destination.add(getL2ID(address, num_l2, l2_select_num_bits, l2_select_low_bit));
        out_msg.MessageSize := MessageSizeType:Data;
        // must write the data to the message so the L2 will have the right data
        in_msg.writeData(out_msg.DataBlk);
        out_msg.Offset := addressOffset(in_msg.PhysicalAddress);
        out_msg.Size := in_msg.Size;
        DPRINTF(RubySlicc, "%s: offset: %d, size: %d\n", address, out_msg.Offset, out_msg.Size);
      }
    }
  }

  action(a_issueAtomicRequest, "aa", desc="Issue an atomic get request") {
    enqueue(requestNetwork_out, RequestMsgVI, latency=issue_latency) {
    out_msg.Address := address;
      out_msg.Type := CoherenceRequestTypeVI:GET_Atom;
      out_msg.Requestor := machineID;
      out_msg.Destination.add(getL2ID(address, num_l2, l2_select_num_bits, l2_select_low_bit));
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }

  action(b_issueAtomicPUT, "ba", desc="Issue an atomic PUT request") {
    enqueue(requestNetworkAtomic_out, RequestMsgVI, latency=issue_latency) {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestTypeVI:PUT_Atom;
      out_msg.Requestor := machineID;
      out_msg.Destination.add(getL2ID(address, num_l2, l2_select_num_bits, l2_select_low_bit));
      out_msg.MessageSize := MessageSizeType:Data;
    }
  }

  action(i_allocateL1CacheBlock, "c", desc="Allocate a cache block") {
    if (is_valid(cache_entry)) {
    } else {
      set_cache_entry(cacheMemory.allocate(address, new Entry));
    }
  }

  action(h_deallocateL1CacheBlock, "d", desc="deallocate a cache block") {
    if (is_valid(cache_entry)) {
      cacheMemory.deallocate(address);
      unset_cache_entry();
    }
  }

  action(m_popMandatoryQueue, "e", desc="Pop the mandatory request queue") {
    mandatoryQueue_in.dequeue();
  }

  action(n_popResponseQueue, "f", desc="Pop the response queue") {
    profileMsgDelay(1, responseNetwork_in.dequeue_getDelayCycles());
  }

  action(p_profileReadMiss, "g", desc="Profile cache miss") {
    peek(mandatoryQueue_in, RubyRequest) {
      cacheMemory.profileMiss(in_msg);
    }
    // profileGPUL1Access(isRead?, isHit?, version)
    profileGPUL1Access(true, false, machineIDToNodeID(machineID));
  }

  action(q_profileReadHit, "q", desc="...") {
    // profileGPUL1Access(isRead?, isHit?, version)
    profileGPUL1Access(true, true, machineIDToNodeID(machineID));
  }

  action(t_profileStoreValid, "tv", desc="..." ) {
    // profileGPUL1Access(isRead?, isHit?, version)
    profileGPUL1Access(false, true, machineIDToNodeID(machineID));
  }

  action(t_profileStoreInvalid, "ti", desc="..." ) {
    // profileGPUL1Access(isRead?, isHit?, version)
    profileGPUL1Access(false, false, machineIDToNodeID(machineID));
  }

  action(r_load_hit, "h", desc="Notify sequencer the load completed.") {
    assert(is_valid(cache_entry));
    DPRINTF(RubySlicc,"%s\n", cache_entry.DataBlk);
    sequencer.readCallback(address,
                           GenericMachineType:L1Cache,
                           cache_entry.DataBlk);
  }

  action(rx_load_hit, "rx", desc="External load completed.") {
    peek(responseNetwork_in, ResponseMsgVI) {
      assert(is_valid(cache_entry));
      DPRINTF(RubySlicc,"%s\n", cache_entry.DataBlk);
      sequencer.readCallback(address,
                             getNondirectHitMachType(in_msg.Sender),
                             cache_entry.DataBlk);
    }
  }

  action(s_store_hit, "i", desc="Notify sequencer that store completed.") {
    // To make Ruby happy. We already wrote the data to L2 in b_issuePUT
    sequencer.writeCallback(address,
                            GenericMachineType:L1Cache,
                            temp_store_data);
    DPRINTF(RubySlicc,"%s %s\n", address, temp_store_data);
  }

   action(sx_store_hit, "sx", desc="External store completed.") {
      assert(is_valid(tbe));
      error("External store hits not supported");
      DPRINTF(RubySlicc,"%s\n", cache_entry.DataBlk);
      sequencer.writeCallback(address,
                              GenericMachineType:Directory,
                              tbe.DataBlk);
  }

  action(u_writeDataToCache, "j", desc="Write data to the cache") {
    peek(responseNetwork_in, ResponseMsgVI) {
      assert(is_valid(cache_entry));
      cache_entry.DataBlk := in_msg.DataBlk;
    }
  }

  action(v_allocateTBE, "k", desc="Allocate TBE") {
    TBEs.allocate(address);
    set_tbe(TBEs[address]);
  }


  action(w_deallocateTBE, "l", desc="Deallocate TBE") {
    TBEs.deallocate(address);
    unset_tbe();
  }

  action(x_copyDataFromCacheToTBE, "m", desc="Copy data from cache to TBE") {
    assert(is_valid(cache_entry));
    assert(is_valid(tbe));
    tbe.DataBlk := cache_entry.DataBlk;
  }

  action(zz_stallAndWaitMandatoryQueue, "\z", desc="Send the head of the mandatory queue to the back of the queue.") {
    stall_and_wait(mandatoryQueue_in, address);
  }

  action(kd_wakeUpDependents, "kd", desc="wake-up dependents") {
    wakeUpBuffers(address);
  }

  action(ka_wakeUpAllDependents, "ka", desc="wake-up all dependents") {
    wakeUpAllBuffers();
  }

  // TRANSITIONS

  transition({IV, IA, IV_a, VI_a}, {Load, Ifetch, Store, Flush_line, Replacement, Atomic}) {} {
    zz_stallAndWaitMandatoryQueue;
  }

  transition(V_a, {Load, Ifetch, Store, Flush_line, Replacement}) {} {
    zz_stallAndWaitMandatoryQueue;
  }

  transition(V, Store, IA) {TagArrayRead, TagArrayWrite} {
    t_profileStoreValid;
    v_allocateTBE;
    b_issuePUT;
    h_deallocateL1CacheBlock;
    ka_wakeUpAllDependents;
    m_popMandatoryQueue;
  }

  transition(I, Store, IA) {TagArrayRead} {
    t_profileStoreInvalid;
    v_allocateTBE;
    b_issuePUT;
    m_popMandatoryQueue;
  }

  transition(V, {Load, Ifetch}) {TagArrayRead, DataArrayRead} {
    q_profileReadHit;
    r_load_hit;
    m_popMandatoryQueue;
  }

  transition(I, {Load, Ifetch}, IV) {TagArrayRead, TagArrayWrite} {
    p_profileReadMiss;
    v_allocateTBE;
    i_allocateL1CacheBlock;
    a_issueRequest;
    m_popMandatoryQueue;
  }

  transition(IV, Data, V) {DataArrayWrite} {
    u_writeDataToCache;
    rx_load_hit;
    w_deallocateTBE;
    ka_wakeUpAllDependents;
    n_popResponseQueue;
  }

  transition(I, Atomic, IV_a) {TagArrayRead} {
    v_allocateTBE;
    i_allocateL1CacheBlock;
    a_issueAtomicRequest;
    p_profileReadMiss;
    m_popMandatoryQueue;
  }

  transition(V, Atomic, IV_a) {TagArrayRead, TagArrayWrite} {
    v_allocateTBE;
    a_issueAtomicRequest;
    m_popMandatoryQueue;
  }

  transition(IV_a, Data, V_a) {} {
    u_writeDataToCache;
    sx_store_hit;
    w_deallocateTBE;
    n_popResponseQueue;
  }

  transition(V_a, Atomic, VI_a) {} {
    m_popMandatoryQueue;

    v_allocateTBE;
    b_issueAtomicPUT;
    x_copyDataFromCacheToTBE;
  }

  transition({I, V}, Replacement, I) {TagArrayWrite} {
    h_deallocateL1CacheBlock;
    ka_wakeUpAllDependents;
  }

  transition(VI_a, Writeback_Ack, I) {} {
    sx_store_hit;
    h_deallocateL1CacheBlock;
    w_deallocateTBE;
    n_popResponseQueue;
  }

  transition(IA, Writeback_Ack, I) {} {
    s_store_hit;
    w_deallocateTBE;
    n_popResponseQueue;
  }

  transition(V, Flush_line, I) {TagArrayRead, TagArrayWrite} {
    h_deallocateL1CacheBlock;
    ka_wakeUpAllDependents;
    m_popMandatoryQueue;
  }

  transition(I, Flush_line) {TagArrayRead} {
    m_popMandatoryQueue;
  }

}

